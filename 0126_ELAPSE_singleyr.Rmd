---
title: "Discussion_single year (ELAPSE)"
author: "Youchen"
date: "01/26/2021"
output:
  slidy_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.width = 6, fig.height = 6, warning=F)
library(dplyr)
library(raster)
library(sf)
library(car)  # for running slr
library(GWmodel)  #gwr
library(ranger) # Random forests
library(caret)  #data partition
library(splitstackshape)   #stratified function in this library is better than createDataPartition in library caret
library(splitTools)
library(APMtools)
library(tidyr)
library(viridis)
library(MASS)
library(tmap)
library(tiff)
```
```{r read data}
eu_bnd <- st_read("../expanse_shp/eu_expanse2.shp")

```



# Location

```{r}
# csv_name <- 'run1_train_2010'
csv_names_slr <- paste0('run2_', c(2002, 2004, 2006, 2008:2012))  #run1_train_nobreak_noxy run1_train_nobreak_xy     run1_train_break_xy      
csv_names <- paste0('run2_', c(2002, 2004, 2006, 2008:2012))
years <- as.list(c(2002, 2004, 2006, seq(2008, 2012)))


slr <- lapply(paste0('data/workingData/SLR_result_all_', csv_names_slr, '.csv'), read.csv)
gwr_df <- lapply(paste0('data/workingData/GWR_result_all_', csv_names_slr, '.csv'), read.csv)
rf <- lapply(paste0('data/workingData/RF_result_all_', csv_names, '.csv'), read.csv)
```


The datasets were randomly divided into training and test data, using 'type_of_st' and 'climate_zone' as stratification.


```{r fig.height=6, fig.width=10}
tmap_mode('plot')

local_crs <- CRS("+init=EPSG:3035")
EU_sp <- lapply(slr, function(df_1){
   SpatialPointsDataFrame(df_1, coords = cbind(df_1$Xcoord, df_1$Ycoord), proj4string = local_crs)})  
maps_l <- lapply(seq_along(EU_sp), function(sp_i){
   sp_p <- EU_sp[[sp_i]]
   map_1 <- tm_shape(sp_p) +
      tm_dots(size = 0.05, col="df_type",   # col = "NO2",          # popup.vars for showing values
              title = paste0('region'),
              palette=c('red','blue'))+
      tm_shape(eu_bnd)+
      tm_borders()+
      tm_layout(title=csv_names[[sp_i]])
   map_1
})
do.call(tmap_arrange, maps_l)
```

# predictor
* Supervised Linear regression (SLR)
* Geographically weighted regression (GWR)
* Random forests (RF)

SLR and GWR:

```{r}
source("scr/fun_call_predictor.R")
pred_c_rf <- c(pred_c, "x_trun", "y_trun")
print(pred_c)
```

RF:

```{r}
print(pred_c_rf)
```



# Performance matrix
* Supervised Linear regression (SLR)
* Geographically weighted regression (GWR)
* Random forests (RF)

Training data was used for training the models using these three algorithms. Then the test data was used for evaluating model performance.

## Test

```{r}
show_EM <- function(slr, gwr, rf, scenario='all'){
   if(scenario=='all'){
      data.frame(slr=error_matrix(slr$obs, slr$slr),
           gwr=error_matrix(gwr$obs, gwr$gwr),
           rf=error_matrix(rf$obs, rf$rf))[c(1,5,7),] %>% print
   }else{
      slr <- slr[slr$df_type==scenario, ]
      gwr <- gwr[gwr$df_type==scenario, ]
      rf <- rf[rf$df_type==scenario, ]
      data.frame(slr=error_matrix(slr$obs, slr$slr),
           gwr=error_matrix(gwr$obs, gwr$gwr),
           rf=error_matrix(rf$obs, rf$rf))[c(1,5,7),] %>% print()
   }
}
for(i in seq_along(csv_names)){
   print(csv_names_slr[i])
   show_EM(slr[[i]], gwr_df[[i]], rf[[i]], 'test')
}

```

## Train

```{r}
for(i in seq_along(csv_names)){
   print(csv_names_slr[i])
   show_EM(slr[[i]], gwr_df[[i]], rf[[i]], 'train')
}

```


# Scatterplots

Observations vs. predictions

```{r}
create_df <- function(slr, gwr, rf, scenario){
   if(scenario=='all'){
      cbind(slr[, c('obs','station_european_code', 'country_code','year','type_of_st','REGION')], data.frame(slr=slr$slr, gwr=gwr$gwr, rf=rf$rf))
   }else{
      slr <- slr[slr$df_type==scenario, ]
      gwr <- gwr[gwr$df_type==scenario, ]
      rf <- rf[rf$df_type==scenario, ]
      cbind(slr[, c('obs','station_european_code', 'country_code','year','type_of_st','REGION')], data.frame(slr=slr$slr, gwr=gwr$gwr, rf=rf$rf))
   }
}
```

```{r}
default.setting <- list(geom_abline(intercept = 0, slope=1), lims(x=c(-10,120), y=c(-10,120)))

```

```{r}
get_density <- function(x, y, ...) {
  dens <- MASS::kde2d(x, y, ...)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  ii <- cbind(ix, iy)
  return(dens$z[ii])
}
```


```{r, fig.width = 6, fig.height = 3}
for(i in seq_along(csv_names)){
   df_3 <- create_df(slr[[i]], gwr_df[[i]], rf[[i]], 'test')
   df_3 <- df_3 %>% mutate_if(is.character, as.factor)
   df_p <- df_3 %>% gather('model','prediction',c(slr, gwr, rf)) %>%
      mutate(model=factor(model, levels = c('slr','gwr','rf')))
   df_p$density <- get_density(df_p$obs, df_p$prediction)
   p1 <- ggplot(df_p)+
      geom_point(aes(prediction, obs, color=density))+
      # geom_bin2d()+
      facet_grid(.~model)+
      default.setting+
      labs(title=strsplit(csv_names[i],'_')[[1]][2])+
      scale_color_viridis()+
      theme(legend.position = "none")
   print(p1)
}
```

By regions:

```{r}
for(i in seq_along(csv_names)){
   df_3 <- create_df(slr[[i]], gwr_df[[i]], rf[[i]], 'test')
   df_3 <- df_3 %>% mutate_if(is.character, as.factor)
   df_p <- df_3 %>% gather('model','prediction',c(slr, gwr, rf)) %>%
      mutate(model=factor(model, levels = c('slr','gwr','rf')))
   df_p$density <- get_density(df_p$obs, df_p$prediction)
   p1 <- ggplot(df_p)+
      geom_point(aes(prediction, obs, color=density))+
      # geom_bin2d()+
      facet_grid(REGION~model)+
      default.setting+
      labs(title=strsplit(csv_names[i],'_')[[1]][3])+
      scale_color_viridis()+
      theme(legend.position = "none")
   print(p1)
}
```

By station types

```{r, fig.width = 6, fig.height = 3}
for(i in seq_along(csv_names)){
   df_3 <- create_df(slr[[i]], gwr_df[[i]], rf[[i]], 'test')
   df_3 <- df_3 %>% mutate_if(is.character, as.factor)
   df_p <- df_3 %>% gather('model','prediction',c(slr, gwr, rf)) %>%
      mutate(model=factor(model, levels = c('slr','gwr','rf')))
   df_p$density <- get_density(df_p$obs, df_p$prediction)
   p1 <- ggplot(df_p)+
      geom_point(aes(prediction, obs, color=density))+
      facet_grid(type_of_st~model)+
      default.setting+
      labs(title=strsplit(csv_names[i],'_')[[1]][3])+
      scale_color_viridis()+
      theme(legend.position = "none")
   print(p1)
}
```


# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
nngbs <- (lapply(paste0("data/workingData/GWR_nngb_", csv_names_slr, ".txt"), read.table) %>% Reduce(rbind,.))[,1]
data.frame(nngb=nngbs, model=csv_names_slr) %>% print
```

```{r}
show_gwr_coef <- function(i){
   
   grid::grid.raster( tiff::readTIFF(paste0("graph/gwr_coef/", csv_names_slr[i],".tiff")) )
}
print(csv_names_slr[1])
show_gwr_coef(1)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[2])
show_gwr_coef(2)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[3])
show_gwr_coef(3)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[4])
show_gwr_coef(4)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[5])
show_gwr_coef(5)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[6])
show_gwr_coef(6)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[7])
show_gwr_coef(7)
```

# Coefficient surface from GWR

* Cell size: 20 km
* Exponential adaptive kernel function

```{r}
print(csv_names_slr[8])
show_gwr_coef(8)
```


# Variable importance from Random forests (Top 15)

```{r, fig.width=5, fig.height=3.5}
source("scr/fun_plot_rf_vi.R")
lapply(csv_names, plot_rf_vi, var_no=15)
```


