---
title: "Discussion_single year (ELAPSE)"
author: "Youchen"
date: "01/26/2021"
output: html_document
  # slidy_presentation: default
  # ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.width = 6, fig.height = 6, warning=F)
source("scr/fun_call_lib.R")
library(kableExtra)
```
```{r read data}
eu_bnd <- st_read("../expanse_shp/eu_expanse2.shp")

```

After the year of 2006, the corine data was linearly interpolated:

```{r read prediction results (5-fold test data)}
# Here we read the predictions for test data from all five-folds
csv_names <- paste0('o_NO2_5cv_', c(2006:2012))
years <- as.list(seq(2006, 2012))
nfold=5
all_test <- lapply(paste0("data/workingData/", csv_names, ".csv"), read.csv)
# lapply(all_test, nrow)
```


The predictors used in SLR, GWR, RF were the same.

```{r predictors in LUR}
source("../expanse_multiyear/src/00_fun_read_data.R")
yr_i=2
csv_name <- csv_names[yr_i]
no2_e_09_11 <- subset_df_yrs(no2_e_all, years[[yr_i]])
source("scr/fun_create_fold.R")
data_all1 <- create_fold(no2_e_09_11, seed, strt_group=c("sta_type", "zoneID"), 
                         multiyr_vargroup = "sta_code", 
                         nfold = nfold)
#f# SLR: select predictors
# source("scr/o_00_01_call_predictor.R")
exc_names <- c("sta_code", "component_code", "component_caption", "obs", 
               "year", "id", "country_name", "sta_type", "area_type", "areaid", 
               "index", "nfold", "xcoord", "ycoord")
pred_c <- names(data_all1)[!names(data_all1)%in%exc_names]
neg_pred <- pred_c[grepl("nat|ugr", pred_c)]
pred_c

```

# Location

The datasets were randomly divided into training and test data, using 'type_of_st' and 'climate_zone' as stratification.


```{r fig.height=6, fig.width=10}
# tmap_mode('plot')
tmap_mode('view')
maps_l <- lapply(seq_along(years), function(yr_i){
   no2_e_09_11 <- subset_df_yrs(no2_e_all, years[[yr_i]])
   # data_all <- no2_e_09_11
   print(paste0("year: ", unique(no2_e_09_11$year)))
   source("scr/fun_create_fold.R")
   data_all1 <- create_fold(no2_e_09_11, seed, strt_group = c("sta_type", "zoneID"))
   EU_sp <- st_as_sf(data_all1, coords = c("xcoord", "ycoord"))
   st_crs(EU_sp) <- st_crs(3035)
   
   map_1 <- tm_shape(EU_sp) +
      tm_dots(size = 0.05, col="nfold",   # col = "NO2",          # popup.vars for showing values
              title = paste0('nfold in year ', unique(no2_e_09_11$year)), palette=viridis(5), style = "cat"  #,  palette=viridis(5), style=="fixed"
      )+
      tm_shape(eu_bnd)+
      tm_borders()
   map_1
})
# do.call(tmap_arrange, maps_l)
maps_l
```

# Five-fold cross-validation

The model performance of GWR kinda vary greatly among folds.

```{r}

show_EM <- function(all_df_i){
   gwr=all_test[[all_df_i]]$gwr
   gwr_rf=all_test[[all_df_i]]$gwr_rf
   slr=all_test[[all_df_i]]$slr
   rf=all_test[[all_df_i]]$rf
   df_all <- data.frame(slr=error_matrix(all_test[[all_df_i]]$obs, slr),
           gwr=error_matrix(all_test[[all_df_i]]$obs, gwr),
           gwr_rf=error_matrix(all_test[[all_df_i]]$obs, gwr_rf),
           rf=error_matrix(all_test[[all_df_i]]$obs, rf),
           yr=years[[all_df_i]])[c(1,5,7),]
   df_all$EM = row.names(df_all)
   df_all
}
em_df <- lapply(seq_along(all_test), show_EM)
em_df <- do.call(rbind, em_df)
ggplot(em_df %>% filter(EM=='rsq') %>%  gather("model", "values", -c("yr", "EM")), aes(x=yr, y=values, fill=model))+
      geom_bar(stat="identity", position = "dodge2")+
      # facet_grid(EM~., scales ='free')+
      # labs(title=years[[i]])+
   labs(y="R squared")+
      theme(axis.title = element_text(size = 18),
          axis.text = element_text(size = 16),
          legend.title = element_text(size = 16),
          legend.text = element_text(size = 16),
          strip.text.y = element_text(size = 15))

ggplot(em_df %>% filter(EM=='RMSE') %>%  gather("model", "values", -c("yr", "EM")), 
       aes(x=yr, y=values, fill=model))+
      geom_bar(stat="identity", position = "dodge2")+
      # facet_grid(EM~., scales ='free')+
      # labs(title=years[[i]])+
   labs(y="RMSE")+
      theme(axis.title = element_text(size = 18),
          axis.text = element_text(size = 16),
          legend.title = element_text(size = 16),
          legend.text = element_text(size = 16),
          strip.text.y = element_text(size = 15))


```

*It is strange that MACC was one of the influential predictors in RF but not included in SLR.*
There are two differences in the predictors of ELAPSE and the current predictors:

1. Population data was obtained from a different data sources: JRC global population counts (2000)
2. Altitude was not included
3. OSM was used and there were 3 classes of road types instead of MAJOR and ALL roads


* The selected predictors are mostly population, impervious density and road data.
* MACC is not selected in SLR but is influential in RF.


```{r selected predictors in slr, fig.width = 10, fig.height = 3.6}
comp_rf_slr <- function(csv_i){
   slr_name <- list.files("data/workingData/", "SLR_summary_model_o")[csv_i]
   yr <- strsplit(slr_name, "_")[[1]][5] %>% as.numeric()
   nfold <- (strsplit(slr_name, "_")[[1]][7] %>% strsplit(., ".csv"))[[1]] %>% as.numeric()
   # rf_name <- paste0("RF_vi_o_", yr, "_fold_", nfold, ".csv")
   slr_result <- read.csv(paste0("data/workingData/", slr_name), header=T)
   slr_result$yr <- yr
   slr_result$nfold <- nfold
   slr_result$increR2[1]=0
   slr_result$incredR2 <- c(0, diff(slr_result$increR2))
   p1 <- ggplot(slr_result)+
      geom_col(aes(x=reorder(variables, incredR2), y=incredR2), 
               position = "dodge2", fill='khaki')+
      coord_flip() +
      theme_light()+
      labs(x = 'variable', y = 'increased R2',
           title = paste0(yr, "_fold_", nfold))+
      # facet_grid(EM~., scales ='free')+
      # labs(title=years[[i]])+
      theme(axis.title = element_text(size = 13),
            axis.text = element_text(size = 13),
            legend.title = element_text(size = 13),
            legend.text = element_text(size = 13),
            strip.text.y = element_text(size = 12))
   # rf_vi <- read.csv(paste0("data/workingData/", rf_name))
   source("scr/fun_plot_rf_vi.R")
   p2 <- plot_rf_vi(paste0("o_", yr, "_fold_", nfold), var_no = 10)
   
   var_importance <- read.csv(paste0('data/workingData/GWR_rf_vi_o_', yr, '_fold_', nfold, '.csv'), 
                              header = T)
   p3 <- ggplot(var_importance %>% top_n(10, vi))+
      geom_col(aes(reorder(var_name, vi), vi),
               position = 'dodge', fill='khaki')+
      coord_flip() +
      theme_light()+
      labs(x = 'variable', y = 'importance value (impurity)',
           title = paste0("GWR_RF_", yr, "_fold_", nfold))+
      theme(axis.title = element_text(size = 11),
            axis.text = element_text(size = 11),
            legend.title = element_text(size = 11),
            legend.text = element_text(size = 11),
            strip.text.y = element_text(size = 11))
   grid.arrange(p1, p2, p3, nrow=1)  
}

# comp_rf_slr(4)
lapply(seq_along(list.files("data/workingData/", "SLR_summary_model_o")), comp_rf_slr)
```

# Performance matrix

* Supervised Linear regression (SLR)
* Geographically weighted regression (GWR)
* Random forests (RF)

Training data was used for training the models using these three algorithms. Then the test data was used for evaluating model performance.

Averaged error matrix from all folds:

## Test

```{r}
# perfm <- lapply(seq_along(years), function(i){
#    perfm <- lapply(paste0("data/workingData/", list.files("data/workingData/", paste0("perf_m_run2_", years[[i]]))), read.csv)
#    perfm <- do.call(rbind, perfm)
#    perfm %>% filter(df_type=="test") %>% group_by(df_type, year, model) %>% summarise(RMSE=mean(RMSE),
#                                                                                       # RRMSE=mean(RRMSE),
#                                                                                       # IQR=mean(IQR),
#                                                                                       # rIQR=mean(rIQR),
#                                                                                       # MAE=mean(MAE),
#                                                                                       # rMAE=mean(rMAE),
#                                                                                       # rsq_sd=sd(rsq),
#                                                                                       rsq=mean(rsq)) %>% 
#       kbl(full_width=F)#,explained_var=mean(explained_var)
# })
# do.call(rbind, perfm)
```




## Train

```{r}
# perfm <- lapply(seq_along(years), function(i){
#    perfm <- lapply(paste0("data/workingData/", list.files("data/workingData/", paste0("perf_m_o_", years[[i]]))), read.csv)
#    perfm <- do.call(rbind, perfm)
#    perfm %>% filter(df_type=="train") %>% group_by(df_type, year, model) %>% summarise(RMSE=mean(RMSE),
#                                                                                       # RRMSE=mean(RRMSE),
#                                                                                       # IQR=mean(IQR),
#                                                                                       # rIQR=mean(rIQR),
#                                                                                       # MAE=mean(MAE),
#                                                                                       # rMAE=mean(rMAE),
#                                                                                       # rsq_sd=sd(rsq),
#                                                                                       rsq=mean(rsq)) %>% 
#       kbl(full_width=F)#,explained_var=mean(explained_var)
# })
# do.call(rbind, perfm)
```



