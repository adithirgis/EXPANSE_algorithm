---
title: "Discussion_multiple year (ELAPSE)"
author: "Youchen"
date: "01/26/2021"
output:
  slidy_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.width = 6, fig.height = 6, warning=F)
library(dplyr)
library(raster)
library(sf)
library(car)  # for running slr
library(GWmodel)  #gwr
library(ranger) # Random forests
library(caret)  #data partition
library(splitstackshape)   #stratified function in this library is better than createDataPartition in library caret
library(splitTools)
library(APMtools)
library(tidyr)
library(viridis)
library(MASS)
library(tmap)
```
```{r read data}
eu_bnd <- st_read("../../../expanse_shp/eu_expanse2.shp")

```



# Location

```{r}
# csv_name <- 'run1_train_2010'
csv_names <- paste0('run1_train_', c('2010', '09-11', '08-12'))
years <- list(2010, 2009:2011, 2008:2012)



slr <- lapply(paste0('../../data/workingData/SLR_result_all_', csv_names, '.csv'), read.csv)
gwr <- lapply(paste0('../../data/workingData/GWR_result_all_', csv_names, '.csv'), read.csv)
rf <- lapply(paste0('../../data/workingData/RF_result_all_', csv_names, '.csv'), read.csv)
```

The datasets were randomly divided into training and test data, using 'type_of_st', 'year', and 'climate_zone' as stratification.


```{r fig.height=6, fig.width=10}
tmap_mode('plot')
EU_data <- slr[[3]]
local_crs <- CRS("+init=EPSG:3035")
EU_sp <- EU_data %>%    
   SpatialPointsDataFrame(data = ., 
                          coords = cbind(EU_data$Xcoord, EU_data$Ycoord),
                          proj4string = local_crs)
tm_shape(EU_sp[EU_sp$year==2010, ]) +
   tm_dots( "climate_zone",size = 0.09,    # col = "NO2",          # popup.vars for showing values
            title = paste0('region'))+
   tm_shape(eu_bnd)+
   tm_borders()
years <- EU_sp$year %>% unique
maps_l <- lapply(years, function(year_i){
   map_1 <- tm_shape(EU_sp[EU_sp$year==year_i, ]) +
      tm_dots(size = 0.05, col="df_type",   # col = "NO2",          # popup.vars for showing values
              title = paste0('region'),
              palette=c('red','blue'))+
      tm_shape(eu_bnd)+
      tm_borders()+
      tm_layout(title=year_i)
   map_1
})
do.call(tmap_arrange, maps_l)
```



# Performance matrix


```{r}
show_EM <- function(slr, gwr, rf, scenario='all'){
   if(scenario=='all'){
      data.frame(slr=error_matrix(slr$obs, slr$slr),
           gwr=error_matrix(gwr$obs, gwr$gwr),
           rf=error_matrix(rf$obs, rf$rf))[c(1,5,7),] %>% print
   }else{
      slr <- slr[slr$df_type==scenario, ]
      gwr <- gwr[gwr$df_type==scenario, ]
      rf <- rf[rf$df_type==scenario, ]
      data.frame(slr=error_matrix(slr$obs, slr$slr),
           gwr=error_matrix(gwr$obs, gwr$gwr),
           rf=error_matrix(rf$obs, rf$rf))[c(1,5,7),] %>% print()
   }
}
for(i in seq_along(csv_names)){
   print(csv_names[i])
   show_EM(slr[[i]], gwr[[i]], rf[[i]], 'test')
}

```
```{r read in gwr}
source('../../scr/fun_gwr.R')
# source('../../scr/fun_plot_gwr.R')
source("../../scr/fun_setupt_gwr.R")
nngbs <- (lapply(paste0("../../data/workingData/GWR_nngb_", csv_names, ".txt"), read.table) %>% Reduce(rbind,.))[,1]

for(i in seq_along(csv_names)){
   train_sub <- slr[[i]] %>% filter(df_type=='train')
   setup <- setup_gwr(train_sub, eu_bnd, 
                      cellsize = 200000, local_crs = CRS("+init=EPSG:3035"))
   sp_train <- setup[[1]]
   grd <- setup[[2]]
   gwr_model <- gwr(sp_train, grd, nngbs[i], csv_names[i])
}

```


```{r}
create_df <- function(slr, gwr, rf, scenario){
   if(scenario=='all'){
      cbind(slr[, c('obs','station_european_code', 'country_code','year','type_of_st','REGION')], data.frame(slr=slr$slr, gwr=gwr$gwr, rf=rf$rf))
   }else{
      slr <- slr[slr$df_type==scenario, ]
      gwr <- gwr[gwr$df_type==scenario, ]
      rf <- rf[rf$df_type==scenario, ]
      cbind(slr[, c('obs','station_european_code', 'country_code','year','type_of_st','REGION')], data.frame(slr=slr$slr, gwr=gwr$gwr, rf=rf$rf))
   }
}
```

```{r}
default.setting <- list(geom_abline(intercept = 0, slope=1), lims(x=c(-10,120), y=c(-10,120)))

```

```{r}
get_density <- function(x, y, ...) {
  dens <- MASS::kde2d(x, y, ...)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  ii <- cbind(ix, iy)
  return(dens$z[ii])
}
```

```{r, fig.width = 6, fig.height = 3}
for(i in seq_along(csv_names)){
   df_3 <- create_df(slr[[i]], gwr[[i]], rf[[i]], 'test')
   df_3 <- df_3 %>% mutate_if(is.character, as.factor)
   df_p <- df_3 %>% gather('model','prediction',c(slr, gwr, rf)) %>% 
      mutate(model=factor(model, levels = c('slr','gwr','rf')))
   df_p$density <- get_density(df_p$obs, df_p$prediction)
   p1 <- ggplot(df_p)+
      geom_point(aes(x=obs, prediction, color=density))+
      # geom_bin2d()+
      facet_grid(.~model)+
      default.setting+
      labs(title=strsplit(csv_names[i],'_')[[1]][3])+
      scale_color_viridis()+
      theme(legend.position = "none")
   print(p1)
}
```


```{r}
for(i in seq_along(csv_names)){
   df_3 <- create_df(slr[[i]], gwr[[i]], rf[[i]], 'test')
   df_3 <- df_3 %>% mutate_if(is.character, as.factor)
   df_p <- df_3 %>% gather('model','prediction',c(slr, gwr, rf)) %>% 
      mutate(model=factor(model, levels = c('slr','gwr','rf')))
   df_p$density <- get_density(df_p$obs, df_p$prediction)
   p1 <- ggplot(df_p)+
      geom_point(aes(x=obs, prediction, color=density))+
      # geom_bin2d()+
      facet_grid(REGION~model)+
      default.setting+
      labs(title=strsplit(csv_names[i],'_')[[1]][3])+
      scale_color_viridis()+
      theme(legend.position = "none")
   print(p1)
}
```


```{r, fig.width = 6, fig.height = 3}
for(i in seq_along(csv_names)){
   df_3 <- create_df(slr[[i]], gwr[[i]], rf[[i]], 'test')
   df_3 <- df_3 %>% mutate_if(is.character, as.factor)
   df_p <- df_3 %>% gather('model','prediction',c(slr, gwr, rf)) %>% 
      mutate(model=factor(model, levels = c('slr','gwr','rf')))
   p1 <- ggplot(df_p)+
      geom_point(aes(obs, prediction, colour=type_of_st))+
      facet_grid(.~model)+
      default.setting+
      labs(title=strsplit(csv_names[i],'_')[[1]][3])
   print(p1)
}
```

# Next step
1. Investigate the differences in the spatial patterns among different algorithms
2. 
3. 

